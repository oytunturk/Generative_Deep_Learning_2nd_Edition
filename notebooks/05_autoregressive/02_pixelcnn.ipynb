{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "206a93a2-e9b0-4ea2-a43f-696faa83ea03",
      "metadata": {
        "id": "206a93a2-e9b0-4ea2-a43f-696faa83ea03"
      },
      "source": [
        "# ðŸ‘¾ PixelCNN from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af9e216-7e84-4f5b-a2db-26aca3bea464",
      "metadata": {
        "id": "1af9e216-7e84-4f5b-a2db-26aca3bea464"
      },
      "source": [
        "In this notebook, we'll walk through the steps required to train your own PixelCNN on the fashion MNIST dataset from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c1e6bbc-6f3b-48ac-a4f3-fde6f739f0ca",
      "metadata": {
        "id": "9c1e6bbc-6f3b-48ac-a4f3-fde6f739f0ca"
      },
      "source": [
        "The code has been adapted from the excellent [PixelCNN tutorial](https://keras.io/examples/generative/pixelcnn/) created by ADMoreau, available on the Keras website."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/generative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YaAvTgrI23C",
        "outputId": "16cb7453-7a0e-4bc2-99d8-c68c4894a1b1"
      },
      "id": "9YaAvTgrI23C",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/generative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download database from Kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/generative/data/epirecipes\"\n",
        "!mkdir -p /content/drive/MyDrive/generative/data/epirecipes\n",
        "%cd /content/drive/MyDrive/generative/data/epirecipes\n",
        "%ls -l\n",
        "#!kaggle datasets download -d hugodarwood/epirecipes --unzip --force\n",
        "%ls -l\n",
        "%cd /content/drive/MyDrive/generative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr5mSJ40I38j",
        "outputId": "509ba710-d569-4495-945e-473493f47a13"
      },
      "id": "rr5mSJ40I38j",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/generative/data/epirecipes\n",
            "total 88389\n",
            "-rw------- 1 root root 55252032 Feb 18 20:39 epi_r.csv\n",
            "-rw------- 1 root root 35249903 Feb 18 20:39 full_format_recipes.json\n",
            "-rw------- 1 root root       65 Feb 18 20:38 kaggle.json\n",
            "-rw------- 1 root root     5122 Feb 18 20:39 recipe.py\n",
            "-rw------- 1 root root     1227 Feb 18 20:39 utils.py\n",
            "total 88389\n",
            "-rw------- 1 root root 55252032 Feb 18 20:39 epi_r.csv\n",
            "-rw------- 1 root root 35249903 Feb 18 20:39 full_format_recipes.json\n",
            "-rw------- 1 root root       65 Feb 18 20:38 kaggle.json\n",
            "-rw------- 1 root root     5122 Feb 18 20:39 recipe.py\n",
            "-rw------- 1 root root     1227 Feb 18 20:39 utils.py\n",
            "/content/drive/MyDrive/generative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6acebfa8-4546-41fd-adaa-2307c65b1b8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6acebfa8-4546-41fd-adaa-2307c65b1b8e",
        "outputId": "5c7d8ea7-4c47-4200-bf33-34bab686f2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers, callbacks\n",
        "\n",
        "from notebooks.utils import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8543166d-f4c7-43f8-a452-21ccbf2a0496",
      "metadata": {
        "id": "8543166d-f4c7-43f8-a452-21ccbf2a0496"
      },
      "source": [
        "## 0. Parameters <a name=\"parameters\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "444d84de-2843-40d6-8e2e-93691a5393ab",
      "metadata": {
        "id": "444d84de-2843-40d6-8e2e-93691a5393ab"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 16\n",
        "PIXEL_LEVELS = 4\n",
        "N_FILTERS = 128\n",
        "RESIDUAL_BLOCKS = 5\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 150"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d65dac68-d20b-4ed9-a136-eed57095ce4f",
      "metadata": {
        "id": "d65dac68-d20b-4ed9-a136-eed57095ce4f"
      },
      "source": [
        "## 1. Prepare the data <a name=\"prepare\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0ed0fc56-d1b0-4d42-b029-f4198f78e666",
      "metadata": {
        "id": "0ed0fc56-d1b0-4d42-b029-f4198f78e666"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "(x_train, _), (_, _) = datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b667e78c-8fa7-4e5b-a2c0-69e50166ef77",
      "metadata": {
        "id": "b667e78c-8fa7-4e5b-a2c0-69e50166ef77"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "def preprocess(imgs_int):\n",
        "    imgs_int = np.expand_dims(imgs_int, -1)\n",
        "    imgs_int = tf.image.resize(imgs_int, (IMAGE_SIZE, IMAGE_SIZE)).numpy()\n",
        "    imgs_int = (imgs_int / (256 / PIXEL_LEVELS)).astype(int)\n",
        "    imgs = imgs_int.astype(\"float32\")\n",
        "    imgs = imgs / PIXEL_LEVELS\n",
        "    return imgs, imgs_int\n",
        "\n",
        "\n",
        "input_data, output_data = preprocess(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e3c2b304-8385-4931-8291-9b7cc462c95e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "e3c2b304-8385-4931-8291-9b7cc462c95e",
        "outputId": "76f9720e-bf67-4c08-9678-167ac1c15dee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show some items of clothing from the training set\n",
        "display(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ccd5cb2-8c7b-4667-8adb-4902f3fa60cf",
      "metadata": {
        "id": "5ccd5cb2-8c7b-4667-8adb-4902f3fa60cf"
      },
      "source": [
        "## 2. Build the PixelCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "847050a5-e4e6-4134-9bfc-c690cb8cb44d",
      "metadata": {
        "id": "847050a5-e4e6-4134-9bfc-c690cb8cb44d"
      },
      "outputs": [],
      "source": [
        "# The first layer is the PixelCNN layer. This layer simply\n",
        "# builds on the 2D convolutional layer, but includes masking.\n",
        "class MaskedConv2D(layers.Layer):\n",
        "    def __init__(self, mask_type, **kwargs):\n",
        "        super(MaskedConv2D, self).__init__()\n",
        "        self.mask_type = mask_type\n",
        "        self.conv = layers.Conv2D(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Build the conv2d layer to initialize kernel variables\n",
        "        self.conv.build(input_shape)\n",
        "        # Use the initialized kernel to create the mask\n",
        "        kernel_shape = self.conv.kernel.get_shape()\n",
        "        self.mask = np.zeros(shape=kernel_shape)\n",
        "        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n",
        "        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
        "        if self.mask_type == \"B\":\n",
        "            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.conv.kernel.assign(self.conv.kernel * self.mask)\n",
        "        return self.conv(inputs)\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        return cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a52f7795-790e-47b0-b724-80be3e3c3666",
      "metadata": {
        "id": "a52f7795-790e-47b0-b724-80be3e3c3666"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(ResidualBlock, self).__init__(**kwargs)\n",
        "        self.conv1 = layers.Conv2D(\n",
        "            filters=filters // 2, kernel_size=1, activation=\"relu\"\n",
        "        )\n",
        "        self.pixel_conv = MaskedConv2D(\n",
        "            mask_type=\"B\",\n",
        "            filters=filters // 2,\n",
        "            kernel_size=3,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "        )\n",
        "        self.conv2 = layers.Conv2D(\n",
        "            filters=filters, kernel_size=1, activation=\"relu\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pixel_conv(x)\n",
        "        x = self.conv2(x)\n",
        "        return layers.add([inputs, x])\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        return cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "19b4508f-84de-42a9-a77f-950fb493db13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19b4508f-84de-42a9-a77f-950fb493db13",
        "outputId": "b9c0af60-cc93-43ca-bd1d-f389c7f0686a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 16, 16, 1)]       0         \n",
            "                                                                 \n",
            " masked_conv2d_8 (MaskedCon  (None, 16, 16, 128)       6400      \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " residual_block_5 (Residual  (None, 16, 16, 128)       53504     \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " residual_block_6 (Residual  (None, 16, 16, 128)       53504     \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " residual_block_7 (Residual  (None, 16, 16, 128)       53504     \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " residual_block_8 (Residual  (None, 16, 16, 128)       53504     \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " residual_block_9 (Residual  (None, 16, 16, 128)       53504     \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " masked_conv2d_14 (MaskedCo  (None, 16, 16, 128)       16512     \n",
            " nv2D)                                                           \n",
            "                                                                 \n",
            " masked_conv2d_15 (MaskedCo  (None, 16, 16, 128)       16512     \n",
            " nv2D)                                                           \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 16, 16, 4)         516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 307460 (1.17 MB)\n",
            "Trainable params: 307460 (1.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
        "x = MaskedConv2D(\n",
        "    mask_type=\"A\",\n",
        "    filters=N_FILTERS,\n",
        "    kernel_size=7,\n",
        "    activation=\"relu\",\n",
        "    padding=\"same\",\n",
        ")(inputs)\n",
        "\n",
        "for _ in range(RESIDUAL_BLOCKS):\n",
        "    x = ResidualBlock(filters=N_FILTERS)(x)\n",
        "\n",
        "for _ in range(2):\n",
        "    x = MaskedConv2D(\n",
        "        mask_type=\"B\",\n",
        "        filters=N_FILTERS,\n",
        "        kernel_size=1,\n",
        "        strides=1,\n",
        "        activation=\"relu\",\n",
        "        padding=\"valid\",\n",
        "    )(x)\n",
        "\n",
        "out = layers.Conv2D(\n",
        "    filters=PIXEL_LEVELS,\n",
        "    kernel_size=1,\n",
        "    strides=1,\n",
        "    activation=\"softmax\",\n",
        "    padding=\"valid\",\n",
        ")(x)\n",
        "\n",
        "pixel_cnn = models.Model(inputs, out)\n",
        "pixel_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442b5ffa-67a3-4b15-a342-eb1eed5e87ac",
      "metadata": {
        "id": "442b5ffa-67a3-4b15-a342-eb1eed5e87ac"
      },
      "source": [
        "## 3. Train the PixelCNN <a name=\"train\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7204789a-2ad3-48bf-b7e8-00d4cab10d9c",
      "metadata": {
        "id": "7204789a-2ad3-48bf-b7e8-00d4cab10d9c"
      },
      "outputs": [],
      "source": [
        "adam = optimizers.Adam(learning_rate=0.0005)\n",
        "pixel_cnn.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "09d327fc-aff8-40e6-b390-d1bff4c06ea6",
      "metadata": {
        "id": "09d327fc-aff8-40e6-b390-d1bff4c06ea6"
      },
      "outputs": [],
      "source": [
        "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "    def __init__(self, num_img):\n",
        "        self.num_img = num_img\n",
        "\n",
        "    def sample_from(self, probs, temperature):  # <2>\n",
        "        probs = probs ** (1 / temperature)\n",
        "        probs = probs / np.sum(probs)\n",
        "        return np.random.choice(len(probs), p=probs)\n",
        "\n",
        "    def generate(self, temperature):\n",
        "        generated_images = np.zeros(\n",
        "            shape=(self.num_img,) + (pixel_cnn.input_shape)[1:]\n",
        "        )\n",
        "        batch, rows, cols, channels = generated_images.shape\n",
        "\n",
        "        for row in range(rows):\n",
        "            for col in range(cols):\n",
        "                for channel in range(channels):\n",
        "                    probs = self.model.predict(generated_images, verbose=0)[\n",
        "                        :, row, col, :\n",
        "                    ]\n",
        "                    generated_images[:, row, col, channel] = [\n",
        "                        self.sample_from(x, temperature) for x in probs\n",
        "                    ]\n",
        "                    generated_images[:, row, col, channel] /= PIXEL_LEVELS\n",
        "\n",
        "        return generated_images\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        generated_images = self.generate(temperature=1.0)\n",
        "        display(\n",
        "            generated_images,\n",
        "            save_to=\"./output/generated_img_%03d.png\" % (epoch),\n",
        "        )\n",
        "\n",
        "\n",
        "img_generator_callback = ImageGenerator(num_img=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "85231056-d4a4-4897-ab91-065325a18d93",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "85231056-d4a4-4897-ab91-065325a18d93",
        "outputId": "3b2e77ac-d0de-40fc-a74b-f2ec1c55270f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.4924"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './output/generated_img_000.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3300ae65a6d0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m pixel_cnn.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-c7ed7d603555>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         display(\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mgenerated_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./output/generated_img_%03d.png\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/generative/notebooks/utils.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(images, n, size, cmap, as_type, save_to)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nSaved to {save_to}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Need this if 'transparent=True', to reset colors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3341\u001b[0m                         ax.patch._cm_set(facecolor='none', edgecolor='none'))\n\u001b[1;32m   3342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3345\u001b[0m     def ginput(self, n=1, timeout=30, show_clicks=True,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2364\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2366\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2367\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2368\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2230\u001b[0m                 \"bbox_inches_restore\"}\n\u001b[1;32m   2231\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptional_kws\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m             print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n\u001b[0m\u001b[1;32m   2233\u001b[0m                 *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n\u001b[1;32m   2234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Let third-parties do as they see fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \"\"\"\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \"\"\"\n\u001b[1;32m    457\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         mpl.image.imsave(\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2426\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output/generated_img_000.png'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "EPOCHS=2\n",
        "pixel_cnn.fit(\n",
        "    input_data,\n",
        "    output_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[tensorboard_callback, img_generator_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfb4fa72-dd2d-44c1-ad18-9c965060683e",
      "metadata": {
        "id": "cfb4fa72-dd2d-44c1-ad18-9c965060683e"
      },
      "source": [
        "## 4. Generate images <a name=\"generate\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7bbd4643-be09-49ba-b7bc-a524a2f00806",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "7bbd4643-be09-49ba-b7bc-a524a2f00806",
        "outputId": "04c48adb-9ac9-4709-a720-97508d3fceb3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ImageGenerator' object has no attribute 'model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-07bd3eefb6f1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_generator_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-c7ed7d603555>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, temperature)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     probs = self.model.predict(generated_images, verbose=0)[\n\u001b[0m\u001b[1;32m     23\u001b[0m                         \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     ]\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ImageGenerator' object has no attribute 'model'"
          ]
        }
      ],
      "source": [
        "generated_images = img_generator_callback.generate(temperature=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "52cadb4b-ae2c-42a9-92ac-68e2131380ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "52cadb4b-ae2c-42a9-92ac-68e2131380ef",
        "outputId": "6d047bd2-bfe0-4aed-9e5e-734dfa3c4110"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(generated_images)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZIMg_WyhTxhD"
      },
      "id": "ZIMg_WyhTxhD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}