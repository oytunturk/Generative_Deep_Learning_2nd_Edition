{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "206a93a2-e9b0-4ea2-a43f-696faa83ea03",
      "metadata": {
        "id": "206a93a2-e9b0-4ea2-a43f-696faa83ea03"
      },
      "source": [
        "# ðŸ‘¾ PixelCNN from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af9e216-7e84-4f5b-a2db-26aca3bea464",
      "metadata": {
        "id": "1af9e216-7e84-4f5b-a2db-26aca3bea464"
      },
      "source": [
        "In this notebook, we'll walk through the steps required to train your own PixelCNN on the fashion MNIST dataset from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c1e6bbc-6f3b-48ac-a4f3-fde6f739f0ca",
      "metadata": {
        "id": "9c1e6bbc-6f3b-48ac-a4f3-fde6f739f0ca"
      },
      "source": [
        "The code has been adapted from the excellent [PixelCNN tutorial](https://keras.io/examples/generative/pixelcnn/) created by ADMoreau, available on the Keras website."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/generative"
      ],
      "metadata": {
        "id": "9YaAvTgrI23C",
        "outputId": "90441543-6d05-4d12-d39f-1b1fd0181239",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9YaAvTgrI23C",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/generative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download database from Kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/generative/data/epirecipes\"\n",
        "!mkdir -p /content/drive/MyDrive/generative/data/epirecipes\n",
        "%cd /content/drive/MyDrive/generative/data/epirecipes\n",
        "%ls -l\n",
        "#!kaggle datasets download -d hugodarwood/epirecipes --unzip --force\n",
        "%ls -l\n",
        "%cd /content/drive/MyDrive/generative"
      ],
      "metadata": {
        "id": "rr5mSJ40I38j"
      },
      "id": "rr5mSJ40I38j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6acebfa8-4546-41fd-adaa-2307c65b1b8e",
      "metadata": {
        "id": "6acebfa8-4546-41fd-adaa-2307c65b1b8e"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers, callbacks\n",
        "\n",
        "from notebooks.utils import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8543166d-f4c7-43f8-a452-21ccbf2a0496",
      "metadata": {
        "id": "8543166d-f4c7-43f8-a452-21ccbf2a0496"
      },
      "source": [
        "## 0. Parameters <a name=\"parameters\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "444d84de-2843-40d6-8e2e-93691a5393ab",
      "metadata": {
        "id": "444d84de-2843-40d6-8e2e-93691a5393ab"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 16\n",
        "PIXEL_LEVELS = 4\n",
        "N_FILTERS = 128\n",
        "RESIDUAL_BLOCKS = 5\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 150"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d65dac68-d20b-4ed9-a136-eed57095ce4f",
      "metadata": {
        "id": "d65dac68-d20b-4ed9-a136-eed57095ce4f"
      },
      "source": [
        "## 1. Prepare the data <a name=\"prepare\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ed0fc56-d1b0-4d42-b029-f4198f78e666",
      "metadata": {
        "id": "0ed0fc56-d1b0-4d42-b029-f4198f78e666",
        "outputId": "1f4fad7f-abe1-410c-e49d-0de4ca2c06ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "(x_train, _), (_, _) = datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b667e78c-8fa7-4e5b-a2c0-69e50166ef77",
      "metadata": {
        "id": "b667e78c-8fa7-4e5b-a2c0-69e50166ef77"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "def preprocess(imgs_int):\n",
        "    imgs_int = np.expand_dims(imgs_int, -1)\n",
        "    imgs_int = tf.image.resize(imgs_int, (IMAGE_SIZE, IMAGE_SIZE)).numpy()\n",
        "    imgs_int = (imgs_int / (256 / PIXEL_LEVELS)).astype(int)\n",
        "    imgs = imgs_int.astype(\"float32\")\n",
        "    imgs = imgs / PIXEL_LEVELS\n",
        "    return imgs, imgs_int\n",
        "\n",
        "\n",
        "input_data, output_data = preprocess(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e3c2b304-8385-4931-8291-9b7cc462c95e",
      "metadata": {
        "id": "e3c2b304-8385-4931-8291-9b7cc462c95e",
        "outputId": "5e6ba6cd-6b70-4c24-aad8-2759fff75d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show some items of clothing from the training set\n",
        "display(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ccd5cb2-8c7b-4667-8adb-4902f3fa60cf",
      "metadata": {
        "id": "5ccd5cb2-8c7b-4667-8adb-4902f3fa60cf"
      },
      "source": [
        "## 2. Build the PixelCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "847050a5-e4e6-4134-9bfc-c690cb8cb44d",
      "metadata": {
        "id": "847050a5-e4e6-4134-9bfc-c690cb8cb44d"
      },
      "outputs": [],
      "source": [
        "# The first layer is the PixelCNN layer. This layer simply\n",
        "# builds on the 2D convolutional layer, but includes masking.\n",
        "class MaskedConv2D(layers.Layer):\n",
        "    def __init__(self, mask_type, **kwargs):\n",
        "        super(MaskedConv2D, self).__init__()\n",
        "        self.mask_type = mask_type\n",
        "        self.conv = layers.Conv2D(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Build the conv2d layer to initialize kernel variables\n",
        "        self.conv.build(input_shape)\n",
        "        # Use the initialized kernel to create the mask\n",
        "        kernel_shape = self.conv.kernel.get_shape()\n",
        "        self.mask = np.zeros(shape=kernel_shape)\n",
        "        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n",
        "        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
        "        if self.mask_type == \"B\":\n",
        "            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.conv.kernel.assign(self.conv.kernel * self.mask)\n",
        "        return self.conv(inputs)\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        return cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a52f7795-790e-47b0-b724-80be3e3c3666",
      "metadata": {
        "id": "a52f7795-790e-47b0-b724-80be3e3c3666"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(ResidualBlock, self).__init__(**kwargs)\n",
        "        self.conv1 = layers.Conv2D(\n",
        "            filters=filters // 2, kernel_size=1, activation=\"relu\"\n",
        "        )\n",
        "        self.pixel_conv = MaskedConv2D(\n",
        "            mask_type=\"B\",\n",
        "            filters=filters // 2,\n",
        "            kernel_size=3,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "        )\n",
        "        self.conv2 = layers.Conv2D(\n",
        "            filters=filters, kernel_size=1, activation=\"relu\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pixel_conv(x)\n",
        "        x = self.conv2(x)\n",
        "        return layers.add([inputs, x])\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        return cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "19b4508f-84de-42a9-a77f-950fb493db13",
      "metadata": {
        "id": "19b4508f-84de-42a9-a77f-950fb493db13",
        "outputId": "c32e4656-f5dd-4223-d342-07a5dfbfbc0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 16, 16, 1)]       0         \n",
            "                                                                 \n",
            " masked_conv2d (MaskedConv2  (None, 16, 16, 128)       6400      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " residual_block (ResidualBl  (None, 16, 16, 128)       53504     \n",
            " ock)                                                            \n",
            "                                                                 \n",
            " residual_block_1 (Residual  (None, 16, 16, 128)       53504     \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " residual_block_2 (Residual  (None, 16, 16, 128)       53504     \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " residual_block_3 (Residual  (None, 16, 16, 128)       53504     \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " residual_block_4 (Residual  (None, 16, 16, 128)       53504     \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " masked_conv2d_6 (MaskedCon  (None, 16, 16, 128)       16512     \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " masked_conv2d_7 (MaskedCon  (None, 16, 16, 128)       16512     \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 16, 16, 4)         516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 307460 (1.17 MB)\n",
            "Trainable params: 307460 (1.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
        "x = MaskedConv2D(\n",
        "    mask_type=\"A\",\n",
        "    filters=N_FILTERS,\n",
        "    kernel_size=7,\n",
        "    activation=\"relu\",\n",
        "    padding=\"same\",\n",
        ")(inputs)\n",
        "\n",
        "for _ in range(RESIDUAL_BLOCKS):\n",
        "    x = ResidualBlock(filters=N_FILTERS)(x)\n",
        "\n",
        "for _ in range(2):\n",
        "    x = MaskedConv2D(\n",
        "        mask_type=\"B\",\n",
        "        filters=N_FILTERS,\n",
        "        kernel_size=1,\n",
        "        strides=1,\n",
        "        activation=\"relu\",\n",
        "        padding=\"valid\",\n",
        "    )(x)\n",
        "\n",
        "out = layers.Conv2D(\n",
        "    filters=PIXEL_LEVELS,\n",
        "    kernel_size=1,\n",
        "    strides=1,\n",
        "    activation=\"softmax\",\n",
        "    padding=\"valid\",\n",
        ")(x)\n",
        "\n",
        "pixel_cnn = models.Model(inputs, out)\n",
        "pixel_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442b5ffa-67a3-4b15-a342-eb1eed5e87ac",
      "metadata": {
        "id": "442b5ffa-67a3-4b15-a342-eb1eed5e87ac"
      },
      "source": [
        "## 3. Train the PixelCNN <a name=\"train\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7204789a-2ad3-48bf-b7e8-00d4cab10d9c",
      "metadata": {
        "id": "7204789a-2ad3-48bf-b7e8-00d4cab10d9c"
      },
      "outputs": [],
      "source": [
        "adam = optimizers.Adam(learning_rate=0.0005)\n",
        "pixel_cnn.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "09d327fc-aff8-40e6-b390-d1bff4c06ea6",
      "metadata": {
        "id": "09d327fc-aff8-40e6-b390-d1bff4c06ea6"
      },
      "outputs": [],
      "source": [
        "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "    def __init__(self, num_img):\n",
        "        self.num_img = num_img\n",
        "\n",
        "    def sample_from(self, probs, temperature):  # <2>\n",
        "        probs = probs ** (1 / temperature)\n",
        "        probs = probs / np.sum(probs)\n",
        "        return np.random.choice(len(probs), p=probs)\n",
        "\n",
        "    def generate(self, temperature):\n",
        "        generated_images = np.zeros(\n",
        "            shape=(self.num_img,) + (pixel_cnn.input_shape)[1:]\n",
        "        )\n",
        "        batch, rows, cols, channels = generated_images.shape\n",
        "\n",
        "        for row in range(rows):\n",
        "            for col in range(cols):\n",
        "                for channel in range(channels):\n",
        "                    probs = self.model.predict(generated_images, verbose=0)[\n",
        "                        :, row, col, :\n",
        "                    ]\n",
        "                    generated_images[:, row, col, channel] = [\n",
        "                        self.sample_from(x, temperature) for x in probs\n",
        "                    ]\n",
        "                    generated_images[:, row, col, channel] /= PIXEL_LEVELS\n",
        "\n",
        "        return generated_images\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        generated_images = self.generate(temperature=1.0)\n",
        "        display(\n",
        "            generated_images,\n",
        "            save_to=\"./output/generated_img_%03d.png\" % (epoch),\n",
        "        )\n",
        "\n",
        "\n",
        "img_generator_callback = ImageGenerator(num_img=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "85231056-d4a4-4897-ab91-065325a18d93",
      "metadata": {
        "tags": [],
        "id": "85231056-d4a4-4897-ab91-065325a18d93",
        "outputId": "a117bb4c-52a2-48f2-f913-f0c9654fc194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "  3/469 [..............................] - ETA: 12:50 - loss: 0.4130"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-68a28eb72fa2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pixel_cnn.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "pixel_cnn.fit(\n",
        "    input_data,\n",
        "    output_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[tensorboard_callback, img_generator_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfb4fa72-dd2d-44c1-ad18-9c965060683e",
      "metadata": {
        "id": "cfb4fa72-dd2d-44c1-ad18-9c965060683e"
      },
      "source": [
        "## 4. Generate images <a name=\"generate\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bbd4643-be09-49ba-b7bc-a524a2f00806",
      "metadata": {
        "id": "7bbd4643-be09-49ba-b7bc-a524a2f00806"
      },
      "outputs": [],
      "source": [
        "generated_images = img_generator_callback.generate(temperature=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52cadb4b-ae2c-42a9-92ac-68e2131380ef",
      "metadata": {
        "id": "52cadb4b-ae2c-42a9-92ac-68e2131380ef"
      },
      "outputs": [],
      "source": [
        "display(generated_images)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}